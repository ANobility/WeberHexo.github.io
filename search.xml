<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hello World</title>
    <url>/2022/08/22/hello-world/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>操作系统笔记（1）- 计算机硬件介绍</title>
    <url>/2022/08/23/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0-%E7%A1%AC%E4%BB%B6%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>操作系统也是一种软件，但是操作系统是一种非常复杂的软件。操作系统提供了几种抽象模型</p>
<blockquote>
<p>文件：对 I&#x2F;O 设备的抽象<br>虚拟内存：对程序存储器的抽象<br>进程：对一个正在运行程序的抽象<br>虚拟机：对整个操作系统的抽象</p>
</blockquote>
<p>学习操作系统可以让我们有效解决并发问题。</p>
<span id="more"></span>
<h1 id="操作系统入门"><a href="#操作系统入门" class="headerlink" title="操作系统入门"></a>操作系统入门</h1><h2 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h2><p>现代计算机系统由一个或多个处理器、主存、打印机、键盘、鼠标、显示器、网络接口以及各种输入&#x2F;输出设备构成。</p>
<p><img src="https://pic.leetcode-cn.com/1612664719-ZmxjpB-os1-1.png"></p>
<p>在硬件的基础之上，有一层软件，这层软件能够响应用户的输入指令达到控制硬件的效果，这种软件被称之为‘操作系统’。</p>
<p>我们一般常见的操作系统主要有 <strong>Windows、Linux、FreeBSD 或 macOS</strong> ，这种带有图形界面的操作系统被称为 <strong>图形用户界面(Graphical User Interface, GUI)，而基于文本、命令行的通常称为 Shell</strong>。<br><img src="https://pic.leetcode-cn.com/1612664723-uBmzJL-os1-2.png"></p>
<h2 id="计算机硬件介绍"><a href="#计算机硬件介绍" class="headerlink" title="计算机硬件介绍"></a>计算机硬件介绍</h2><h3 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h3><p>CPU 是计算机的大脑，它主要和内存进行交互，从内存中提取指令并执行它。一个 CPU 的执行周期是从内存中提取第一条指令、解码并决定它的类型和操作数，执行，然后再提取、解码执行后续的指令。重复该循环直到程序运行完毕。</p>
<p>中央处理单元（CPU）主要由运算器、控制器、寄存器三部分组成，从字面意思看运算器就是起着运算的作用，控制器就是负责发出CPU每条指令所需要的信息，寄存器就是保存运算或者指令的一些临时文件，这样可以保证更高的速度。</p>
<p>CPU都有一组特殊的可以执行的指令集，主要分为X86架构和ARM架构。<br>CPU架构可以被分为两大类，即所谓的“复杂指令集”与“精简指令集”系统，也就是经常看到的“CISC”与“RISC”。 Intel和ARM处理器的第一个区别是，前者使用复杂指令（CISC)，而后者使用精简指令集（RISC）。</p>
<p>可以这么说，X86指令集中的指令是复杂的，一条很长指令就可以很多功能，而ARM指令集的指令是很精简的，需要几条精简的短指令完成很多功能。例如吃饭，在x86系统中就是一条长指令，而吃菜又是一条长指令；在ARM中 吃饭&#x3D;张嘴+夹饭+送到嘴里+闭上嘴+咽下去，而吃菜&#x3D;张嘴+夹菜+送到嘴里+闭上嘴+咽下去 一系列简单的指令构成。</p>
<p>X86的方向是高性能方向，因为它追求一条指令完成很多功能，而ARM的方向是面向低功耗，要求指令尽可能精简。X86和ARM的各自主要方向决定了他们的市场。X86的市场主要是PC和服务器，因为需要高性能。ARM的市场主要是手机和平板，因为需要低功耗。</p>
<p>由于访问内存获取执行或数据要比执行指令花费的时间长，因此所有的 CPU 内部都会包含一些寄存器来保存关键变量和临时结果。因此，在指令集中通常会有一些指令用于把关键字从内存中加载到寄存器中，以及把关键字从寄存器存入到内存中。还有一些其他的指令会把来自寄存器和内存的操作数进行组合，例如 add 操作就会把两个操作数相加并把结果保存到内存中。</p>
<h3 id="多线程和多核芯片"><a href="#多线程和多核芯片" class="headerlink" title="多线程和多核芯片"></a>多线程和多核芯片</h3><p>多线程（multithereading） 由Intel公司提出，X86处理器大部分是多线程的，近似地说，多线程允许 CPU 保持两个不同的线程状态并且在纳秒级(nanosecond) 的时间完成切换。线程是一种轻量级的进程，我们会在后面说到。例如，如果一个进程想要从内存中读取指令(这通常会经历几个时钟周期)，多线程 CPU 则可以切换至另一个线程。多线程不会提供真正的并行处理。在一个时刻只有一个进程在运行。</p>
<blockquote>
<p><strong>进程</strong>：一个在内存中运行的应用程序。每个进程都有自己独立的一块内存空间，一个进程可以有多个线程，且至少有一个线程。<br><strong>线程</strong>：与进程不同的是同类的多个线程共享进程的堆和方法区资源，但每个线程有自己的程序计数器、虚拟机栈和本地方法栈，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。<br><strong>根本区别</strong>：进程是操作系统资源分配的基本单位，而线程是处理器任务调度和执行的基本单位。</p>
</blockquote>
<blockquote>
<p><strong>并行</strong>：同时进行，如：一边打电话，一边炒菜；<br><strong>并发</strong>：在一段时间内交替进行，显得好像是“同时”进行，如：在厨房炒菜，听到座机响了，于是去客厅接电话，然后再回到厨房炒菜，再去客厅接电话……<br>单 CPU 多线程提供的是并发能力；而多 CPU 则可以提供并行能力</p>
</blockquote>
<h3 id="存储器"><a href="#存储器" class="headerlink" title="存储器"></a>存储器</h3><p>计算机中第二个主要的组件就是存储器。理想情况下，存储器应该非常快速(比执行一条指令要快，从而不会拖慢 CPU 执行效率)，而且足够大且便宜，但是目前的技术手段无法满足三者的需求。于是采用了不同的处理方式，存储器系统采用一种分层次的结构</p>
<p><img src="https://pic.leetcode-cn.com/1612665300-EydqrQ-os3-1.png"></p>
<h4 id="寄存器"><a href="#寄存器" class="headerlink" title="寄存器"></a>寄存器</h4><p>存储器的顶层是 CPU 中的寄存器，它们用和 CPU 一样的材料制成，所以和 CPU 一样快。程序必须在软件中自行管理这些寄存器</p>
<h4 id="高速缓冲-cache"><a href="#高速缓冲-cache" class="headerlink" title="高速缓冲 cache"></a>高速缓冲 cache</h4><p>位于寄存器下面的是高速缓存，大多集成在CUP内部。<br>CPU先查询Cache中是否有数据，如果有，直接读取即可。</p>
<p>如果Cache中没有，则从内存中读取数据，同时把数据放入Cache中，然后把数据返回给CPU。<br>整个流程其实很简单，但对于Cache和内存信息的交换，需要考虑一些问题：</p>
<p>对于CPU读取数据，如果Cache中没有数据，从内存中读取数据后，如何分配到Cache中？<br>如果Cache满了，采用什么策略替换？<br>对于CPU写入数据，如何保证Cache和内存数据的一致性？<br>对于这3个问题，下面依次来分析是如何解决的。<br>这些问题的答案可以参考<a href="http://kaito-kidd.com/2018/08/23/computer-system-cpu-cache/">Kaito大佬的博客</a></p>
<h4 id="主内存"><a href="#主内存" class="headerlink" title="主内存"></a>主内存</h4><p>主内存也叫主存，通常包括RAM（Random Access Memory）和ROM（Read Only Memory），其他还有EEPROM（Electrically Erasable PROM）和闪存（Flash Memory）。</p>
<blockquote>
<p><strong>RAM</strong>:RAM又称随机存取存储器，存储单元的内容可按照需要随机取出或存入，且存取的速度与存储单元的位置无关。这种存储器在断电时，将丢失其存储内容，所以主要用于存储短时间使用的程序。它主要用来存储程序中用到的变量。凡是整个程序中，所用到的需要被改写的量（包括全局变量、局部变量、堆栈段等），都存储在RAM中。<br><strong>ROM</strong>:它是一种只能读出事先所存的数据的固态半导体存储器。ROM中所存数据稳定，一旦存储数据就再也无法将之改变或者删除，断电后所存数据也不会消失。其结构简单，因而常用于存储各种固化程序和数据。<br>为了便于使用和大批量生产，进一步发展出了可编程只读存储器（PROM）、可擦除可编程只读存储器（EPROM）。EPROM需要用紫外线长时间照射才能擦除，使用很不方便。1980s又出现了电可擦除可编程只读存储器（EEPROM），它克服了EPROM的不足，但是集成度不高、价格较贵。于是又发展出了一种新型的存储单元结构同EPROM类似的快闪存储器（FLASH MEMORY）。FLASH集成度高、功耗低、体积小，又能在线快速擦除，因而获得了快速发展。</p>
</blockquote>
<h4 id="磁盘-x2F-硬盘"><a href="#磁盘-x2F-硬盘" class="headerlink" title="磁盘&#x2F;硬盘"></a>磁盘&#x2F;硬盘</h4><p>这一类的存储器也叫外部存储器&#x2F;辅助存储器，或者外存&#x2F;辅存，一般处理速度较慢、价格较低、容量较大。</p>
<h4 id="虚拟内存机制"><a href="#虚拟内存机制" class="headerlink" title="虚拟内存机制"></a>虚拟内存机制</h4><p>这种机制使得期望运行的存储空间大于实际的物理存储空间。其方法是将程序放在磁盘上，而将主存作为一部分缓存，用来保存最频繁使用的部分程序，这种机制需要快速映像内存地址，用来把程序生成的地址转换为有关字节在 RAM 中的物理地址。这种映像由 CPU 中的一个称为 存储器管理单元(Memory Management Unit, MMU) 的部件来完成。</p>
<h3 id="I-x2F-O设备（Defalt）"><a href="#I-x2F-O设备（Defalt）" class="headerlink" title="I&#x2F;O设备（Defalt）"></a>I&#x2F;O设备（Defalt）</h3><p>实现I&#x2F;O的方式有四种，分别为：</p>
<p>程序直接控制方式，会造成忙等待。<br>中断驱动方式，做到了CPU和I&#x2F;O设备并行工作。<br>DMA方式，彻底解放了CPU。<br>通道控制方式，实现CPU、通道和I&#x2F;O设备三者的并行操作。<br>举个通俗易懂的例子助大家理解：<br>想象一位客户（CPU）要去裁缝店（I&#x2F;O设备）做一批衣服，</p>
<p>程序直接控制，客户必须每隔一段时间去裁缝店看看裁缝把衣服做好没有，浪费客户不少时间。<br>中断驱动，裁缝店有客户的联系方式了，每做好一件衣服就给客户打个电话，让客户来拿，仍然比较浪费时间。<br>DMA，客户有了个单线秘书，并向秘书交代把衣服放在一个仓库，裁缝直接联系秘书，秘书负责把衣服取回来并放在合适的位置，每处理完100件衣服，才向客户报告一次，大大节省了客户的时间。<br>通道，秘书拥有更高的自主权，如可以决定把衣服放在哪里，何时向客户报告。相比于DMA，通道的优势在于如果客户在多个裁缝那里订了货，一个DMA的秘书只能与一个裁缝沟通，而一个通道的秘书可以与多名裁缝进行沟通。</p>
<h3 id="总线"><a href="#总线" class="headerlink" title="总线"></a>总线</h3><p>总线（Bus）是计算机各种功能部件之间传送信息的公共通信干线。总线是一种内部结构，它是 cpu、内存、I&#x2F;O设备传递信息的公用通道，主机的各个部件通过总线相连接，外部设备通过相应的接口电路再与总线相连接，从而形成了计算机硬件系统。</p>
<p>总线可以分为以下三大类：片内总线、系统总线和通信总线</p>
<h4 id="片内总线"><a href="#片内总线" class="headerlink" title="片内总线"></a>片内总线</h4><p>片内总线是指芯片内部的总线，如在 CPU 芯片内部，寄存器与寄存器之间、寄存器与算逻单元 ALU 之间都由 片内总线连接。</p>
<h4 id="系统总线"><a href="#系统总线" class="headerlink" title="系统总线"></a>系统总线</h4><p>系统总线可以分为三个：数据总线、地址总线和控制总线</p>
<p>系统总线是指 CPU、主存、IO 设备（通过I&#x2F;O接口）各大部件之间的信息传输线。由于这些部件通常都安放在主板或各个插件板(插卡)上，故又称板级总线(在一块电路板上各芯片间的连线)或板间总线</p>
<p><img src="https://img-blog.csdnimg.cn/20190813145834413.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3N0YXJ0ZXJfX19fXw==,size_16,color_FFFFFF,t_70"></p>
<blockquote>
<p><strong>数据总线</strong>：<br>数据总线用来传输各功能部件之间的数据信息，它是双向传输总线，其位数与机器字长、存储字长有关，一般为 8 位、16 位或 32 位。数据总线的位数称为数据总线宽度，它是衡量系统性能的一个重要参数。</p>
</blockquote>
<blockquote>
<p><strong>地址总线</strong>：<br>地址总线主要用来指出数据总线上的源数据或目的数据在主存单元的地址或 I&#x2F;O 设备的地址。例如，欲从存储器读出一个数据，则 CPU 要将此数据所在存储单元的地址送到地址线上。又如，欲将某数据经 I&#x2F;O 设备输出，则 CPU 除了需将数据送到数据总线外，还需将该输出设备的地址（通常都经 I&#x2F;O 接口）送到地址总线上。可见,地址总线上的代码是用来指明 CPU 欲访问的存储单元或 I&#x2F;O 端口的地址,由 CPU 输出，单向传输。地址线的位数与存储单元的个数有关，如地址线为 20 根，则对应的存储单元个数为 220。</p>
</blockquote>
<blockquote>
<p><strong>控制总线</strong>：<br>由于数据总线、地址总线都是被挂在总线上的所有部件共享的，如何使各部件能在不同时刻占有总线使用权，需依靠控制总线来完成，因此控制总线是用来发出各种控制信号的传输线。<br>通常对任一控制线而言，它的传输是单向的。例如，存储器读&#x2F;写命令或 I&#x2F;O 设备读&#x2F;写命令都是由 CPU 发出的。<br>但对于控制总线总体来说，又可认为是双向的。例如，当某设备准备就绪时，便向 CPU 发中断请求；当某部件（如 DMA 接口）需获得总线使用权时，也向 CPU 发出总线请求。<br>此外，控制总线还起到监视各部件状态的作用。例如，查询该设备是处于“忙”还是“闲”，是否出错等。因此对 CPU 而言，控制信号既有输出，又有输入。<br>常见的控制信号如下：</p>
<ul>
<li>时钟：用来同步各种操作。</li>
<li>复位：初始化所有部件。</li>
<li>总线请求：表示某部件需获得总线使用权。</li>
<li>总线允许：表示需要获得总线使用权的部件已获得了控制权。</li>
<li>中断请求：表示某部件提出中断请求。</li>
<li>中断响应：表示中断请求已被接收。</li>
<li>存储器写：将数据总线上的数据写至存储器的指定地址单元内。</li>
<li>存储器读：将指定存储单元中的数据读到数据总线上。</li>
<li>I&#x2F;O读：从指定的I&#x2F;O端口将数据读到数据总线上。</li>
<li>I&#x2F;O写：将数据总线上的数据输出到指定的I0端口内。</li>
<li>传输响应：表示数据已被接收,或已将数据送至数据总线上。</li>
</ul>
</blockquote>
<h4 id="通信总线"><a href="#通信总线" class="headerlink" title="通信总线"></a>通信总线</h4><p>通信是用于计算机系统之间或计算机系统与其他系统（如远程通信设备、测试设备）之间信息传送的总线，通信总线也称为外部总线。</p>
<p>更多关于总线的知识请看博客<a href="https://blog.51cto.com/yang/3023701">总线介绍</a></p>
<h3 id="计算机启动过程"><a href="#计算机启动过程" class="headerlink" title="计算机启动过程"></a>计算机启动过程</h3><p>计算机的启动步骤主要分为四步，BIOS → 主引导记录 → 硬盘启动 → 操作系统</p>
<h4 id="BIOS"><a href="#BIOS" class="headerlink" title="BIOS"></a>BIOS</h4><p>当电源开关启动后，主板会通电并初始化固件（即芯片集等），而BIOS（Basic Input Output System 基本输入输出系统）的运行代码则早已被刷入集成在主板的ROM芯片中。</p>
<p>BIOS程序首先检查，计算机硬件能否满足运行的基本条件，这叫做”硬件自检”（Power-On Self-Test），缩写为POST。如果硬件出现问题，主板会发出不同含义的蜂鸣，启动中止。如果没有问题，屏幕就会显示出CPU、内存、硬盘等信息。</p>
<p>硬件自检完成后，BIOS把控制权转交给下一阶段的启动程序。这时，BIOS需要知道，”下一阶段的启动程序”具体存放在哪一个设备。也就是说，BIOS需要有一个外部储存设备的排序，排在前面的设备就是优先转交控制权的设备。这种排序叫做”启动顺序”（Boot Sequence）。</p>
<h4 id="主引导记录"><a href="#主引导记录" class="headerlink" title="主引导记录"></a>主引导记录</h4><p>计算机中可能存在有许多个存储设备，诸如硬盘、可移动硬盘、U盘等等，这些设备按用户预先设置好的优先级安排一个“启动顺序”。BIOS则根据这个顺序将计算机的控制权交给排在第一位的存储设备.<br>BIOS按照”启动顺序”，把控制权转交给排在第一位的储存设备。这时，计算机读取该设备的第一个扇区（0号扇区），也就是读取最前面的512个字节。如果这512个字节的最后两个字节是0x55和0xAA，表明这个设备可以用于启动；如果不是，表明设备不能用于启动，控制权于是被转交给”启动顺序”中的下一个设备。这最前面的512个字节，就叫做”主引导记录”（Master boot record，缩写为MBR）。</p>
<p>“主引导记录”只有512个字节，放不了太多东西。它的主要作用是，告诉计算机到硬盘的哪一个位置去找操作系统。主引导记录由三个部分组成</p>
<blockquote>
<p>第1-446字节：调用操作系统的机器码。<br>第447-510字节：分区表(Partition table)<br>第511-512字节：主引导记录签名(0x55和0xAA)<br>其中，第二部分”分区表”的作用，是将硬盘分成若干个区。</p>
</blockquote>
<p>硬盘分区有很多好处。考虑到每个区可以安装不同的操作系统，”主引导记录”因此必须知道将控制权转交给哪个区。分区表的长度只有64个字节，里面又分成四项，每项16个字节。所以，一个硬盘最多只能分四个一级分区，又叫做”主分区”。每个主分区的16个字节，由6个部分组成。</p>
<blockquote>
<p>第1个字节：如果为0x80，就表示该主分区是激活分区，控制权要转交给这个分区。四个主分区里面只能有一个是激活的。</p>
</blockquote>
<blockquote>
<p>第2-4个字节：主分区第一个扇区的物理位置（柱面、磁头、扇区号等等）。<br>第5个字节：主分区类型。<br>第6-8个字节：主分区最后一个扇区的物理位置。<br>第9-12字节：该主分区第一个扇区的逻辑地址。<br>第13-16字节：主分区的扇区总数。<br>最后的四个字节（”主分区的扇区总数”），决定了这个主分区的长度。也就是说，一个主分区的扇区总数最多不超过2的32次方。如果每个扇区为512个字节，就意味着单个分区最大不超过2TB。再考虑到扇区的逻辑地址也是32位，所以单个硬盘使用MBR分区表类型可利用的空间最大也不超过2TB。如果想使用更大的硬盘，只有2个方法：一是提高每个扇区的字节数，二是增加扇区总数。也就是GPT分区表类型。</p>
</blockquote>
<p>相关问题请见<a href="https://zhuanlan.zhihu.com/p/114350934">MBR和GPT区别</a></p>
<h4 id="硬盘启动"><a href="#硬盘启动" class="headerlink" title="硬盘启动"></a>硬盘启动</h4><p>这时，计算机的控制权就要转交给硬盘的某个分区了，这里又分成三种情况。</p>
<ol>
<li><p>情况A：卷引导记录<br>上一节提到，四个主分区里面，只有一个是激活的。计算机会读取激活分区的第一个扇区，叫做”卷引导记录”（Volume boot record，缩写为VBR）。<br>“卷引导记录”的主要作用是，告诉计算机，操作系统在这个分区里的位置。然后，计算机就会加载操作系统了。</p>
</li>
<li><p>情况B：扩展分区和逻辑分区<br>随着硬盘越来越大，四个主分区已经不够了，需要更多的分区。但是，分区表只有四项，因此规定有且仅有一个区可以被定义成”扩展分区”（Extended partition）。<br>所谓”扩展分区”，就是指这个区里面又分成多个区。这种分区里面的分区，就叫做”逻辑分区”（logical partition）。<br>计算机先读取扩展分区的第一个扇区，叫做”扩展引导记录”（Extended boot record，缩写为EBR）。它里面也包含一张64字节的分区表，但是最多只有两项（也就是两个逻辑分区）。<br>计算机接着读取第二个逻辑分区的第一个扇区，再从里面的分区表中找到第三个逻辑分区的位置，以此类推，直到某个逻辑分区的分区表只包含它自身为止（即只有一个分区项）。因此，扩展分区可以包含无数个逻辑分区。但是，似乎很少通过这种方式启动操作系统。如果操作系统确实安装在扩展分区，一般采用下一种方式启动。</p>
</li>
<li><p>情况C：启动管理器<br>在这种情况下，计算机读取”主引导记录”前面446字节的机器码之后，不再把控制权转交给某一个分区，而是运行事先安装的”启动管理器”（boot loader），由用户选择启动哪一个操作系统。</p>
</li>
</ol>
<h4 id="操作系统-1"><a href="#操作系统-1" class="headerlink" title="操作系统"></a>操作系统</h4><p>控制权转交给操作系统后，操作系统的内核首先被载入内存。</p>
<p>以Linux系统为例，先载入&#x2F;boot目录下面的kernel。内核加载成功后，第一个运行的程序是&#x2F;sbin&#x2F;init。它根据配置文件（Debian系统是&#x2F;etc&#x2F;initab）产生init进程。这是Linux启动后的第一个进程，pid进程编号为1，其他进程都是它的后代。然后，init线程加载系统的各个模块，比如窗口程序和网络程序，直至执行&#x2F;bin&#x2F;login程序，跳出登录界面，等待用户输入用户名和密码。至此，全部启动过程完成。</p>
]]></content>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统笔记（2）- 操作系统概念与结构</title>
    <url>/2022/08/24/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E5%BF%B5%E4%B8%8E%E7%BB%93%E6%9E%84/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="操作系统概念"><a href="#操作系统概念" class="headerlink" title="操作系统概念"></a>操作系统概念</h1><h2 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h2><p>进程：正在进行的一个过程或者说一个任务。而负责执行任务则是cpu。</p>
<p>系统中的程序可以按照顺序执行，也可以并发执行。其中在顺序执行的过程中主要的特点就是顺序性、封闭性和可再现性，而并发执行的程序，破坏了程序的封闭性和可再现性，使得程序和执行程序的活动不再一一对应，这就涉及到了进程之间的同步和互斥问题</p>
<p>进程状态的描述有两种模型，一种是三态模型，另一种是五态模型，下边我们就分别介绍下这两种模型。</p>
<span id="more"></span>
<h3 id="三态模型"><a href="#三态模型" class="headerlink" title="三态模型"></a>三态模型</h3><p><img src="https://pic4.zhimg.com/v2-b1a27ac5c0215c1eecf8442becb7b32b_r.jpg"><br>系统中进程在处理器上交替运行，状态也在不断的发生变化，所以进程一般有三种状态，即运行、就绪、阻塞，关于这三种状态的描述如下：</p>
<blockquote>
<p><strong>运行</strong>，当一个进程在处理机上运行时，就称这个进程处于运行状态。<br><strong>就绪</strong>，一个进程获得了除处理机外的一切资源，一旦得到处理机即可运行，就称这个进程处于就绪状态。<br><strong>阻塞</strong>，阻塞也叫做等待或睡眠状态，一个进程正在等待某一事件发生而暂时停止运行，这时即使处理机分配进程也无法运行，所以称这个进程处于阻塞状态。</p>
</blockquote>
<h3 id="五态模型"><a href="#五态模型" class="headerlink" title="五态模型"></a>五态模型</h3><p><img src="https://pic4.zhimg.com/v2-3c2b7407e66f64c841fb84134436efff_r.jpg"></p>
<h3 id="进程的通讯"><a href="#进程的通讯" class="headerlink" title="进程的通讯"></a>进程的通讯</h3><p>在系统中存在多个可以并发执行的进程，所以进程之间必然存在资源共享和相互合作的情况，也就是进程之间的通信。对于进程之间的通信而言，最重要的概念就是同步和互斥，其中同步指的是合作进程之间的直接制约问题，互斥是申请临界资源进程之间的间接制约问题。下边，我们就来说一下关于同步和互斥的概念。</p>
<p>进程之间的同步，在计算机中多个进程可以并发执行，每个进程都以独立、不可预知的速度向前推进，但是需要在某些确定点上协调相互合作进程间的工作，所以进程之间的同步是进程间完成一项任务时直接发生相互作用的关系。</p>
<p>进程之间的互斥，计算机中各进程之间可以共享各类资源，但有些资源一次只能提供一个进程使用，这些资源称之为临界资源，也就是说进程之间的互斥是系统中各进程互斥使用临界资源。</p>
<h3 id="进程的调度"><a href="#进程的调度" class="headerlink" title="进程的调度"></a>进程的调度</h3><p>进程调度是指如何按照进程的优先级分配CPU，调度的方式有可剥夺和不可剥夺两种方式，其中前者是指当有更高优先级进程到来时，强行将正在运行进程的CPU分配给更高优先级的进程，后者是指当有更高优先级的进程到来时，必须等到正在运行进程自动释放占用的CPU，然后将CPU分配给高优先级的进程。</p>
<h3 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h3><p>死锁是指两个以上的进程互相都因请求对方已经占有的资源，无限期地等待并无法继续运行下去的现象。 死锁是系统的一种出错状态，它浪费系统资源，还会导致整个系统崩溃，所以应该尽量预防和避免死锁。</p>
<p><strong>产生死锁的原因</strong>：资源竞争及进程推进顺序非法。产生死锁的4个必要条件是互斥条件、请求保持条件、不可剥夺条件和环路条件。 <br><strong>解决死锁的策略</strong>：死锁的处理策略主要有4种：鸵鸟策略（即不理睬策略）、预防策略（破坏死锁的4个必要条件之一）、避免策略（精心地分配资源，动态地回避死锁）、检测与解除死锁（一旦发生死锁，系统不但能检测出，还能解除）。 </p>
<h3 id="线程"><a href="#线程" class="headerlink" title="线程"></a>线程</h3><p>传统进程有两个属性，即可拥有资源的独立单位、可独立调度和分配的基本单位。由于在进程的创建、撤销和切换中，系统必须为之付出较大的时空开销，所以在系统中设置的进程数目不宜过多，进程切换的频率不宜太高，这就限制了并发程度的提高。引入线程之后将传统进程的两个基本属性分开，线程作为调度和分配的基本单位，进程作为独立分配资源的单位。用户可以通过创建线程来完成任务，以减少程序并发执行时付出的时空开销。</p>
<p>线程是进程中的一个实体，是被系统独立分配和调度的基本单位。线程基本上不拥有资源，只拥有一点运行中必不可少的资源，它可与同属一个进程的其他线程共享进程所拥有的全部资源。</p>
<p>线程有就绪、运行、阻塞三个基本状态。由于线程具有许多传统进程所具有的特性，在线程中可以创建另一个线程，同一个进程中多个线程可以并发运行。</p>
<p>线程分为用户级线程和内核支持线程两大类。用户级线程不依赖内核，这类线程的创建、撤销和切换都不利用系统调用来实现。内核支持线程依赖于内核，也就是说无论在用户进程中的线程还是在系统中的线程，它们的创建、撤销、切换都利用系统调用来实现。</p>
<p>和线程不同的是，不论是系统进程还是用户进程，在执行切换时，都要依赖内核中的进程调度。因此不管是什么进程都和内核有关，都是在内核的支持下进行切换的。尽管线程和进程表面上看起来相似，但它们本质上是不同的。</p>
<h2 id="地址空间"><a href="#地址空间" class="headerlink" title="地址空间"></a>地址空间</h2><p>每台计算机都有一些主存用来保存正在执行的程序。在一个非常简单的操作系统中，仅仅有一个应用程序运行在内存中。为了运行第二个应用程序，需要把第一个应用程序移除才能把第二个程序装入内存。</p>
<p>复杂一些的操作系统会允许多个应用程序同时装入内存中运行。为了防止应用程序之间相互干扰（包括操作系统），需要有某种保护机制。虽然此机制是在硬件中实现，但却是由操作系统控制的。</p>
<p>上述观点涉及对计算机主存的管理和保护。另一种同等重要并与存储器有关的内容是管理进程的地址空间。通常，每个进程有一些可以使用的地址集合，典型值从 0 开始直到某个最大值。一个进程可拥有的最大地址空间小于主存。在这种情况下，即使进程用完其地址空间，内存也会有足够的内存运行该进程。</p>
<p>但是，在许多 32 位或 64 位地址的计算机中，分别有 2^32 或 2^64 字节的地址空间。如果一个进程有比计算机拥有的主存还大的地址空间，而且该进程希望使用全部的内存，那该怎么处理？在早期的计算机中是无法处理的。但是现在有了一种虚拟内存的技术，正如前面讲到过的，操作系统可以把部分地址空间装入主存，部分留在磁盘上，并且在需要时来回交换它们.</p>
<h3 id="逻辑地址、线性地址、物理地址和虚拟地址的区别"><a href="#逻辑地址、线性地址、物理地址和虚拟地址的区别" class="headerlink" title="逻辑地址、线性地址、物理地址和虚拟地址的区别"></a>逻辑地址、线性地址、物理地址和虚拟地址的区别</h3><blockquote>
<p><strong>逻辑地址（Logical Address）</strong> 是指由程式产生的和段相关的偏移地址部分。例如，你在进行 C 语言指针编程中，能读取指针变量本身值( &amp;操作 )，实际上这个值就是逻辑地址，他是相对于你当前进程数据段的地址，不和绝对物理地址相干。只有在 Intel 实模式下，逻辑地址才和物理地址相等（因为实模式没有分段或分页机制，cpu不进行自动地址转换）；逻辑也就是在Intel保护模式下程式执行代码段限长内的偏移地址（假定代码段、数据段如果完全相同）。应用程式员仅需和逻辑地址打交道，而分段和分页机制对你来说是完全透明的，仅由系统编程人员涉及。应用程式员虽然自己能直接操作内存，那也只能在操作系统给你分配的内存段操作。</p>
</blockquote>
<blockquote>
<p><strong>线性地址（Linear Address）</strong> 是逻辑地址到物理地址变换之间的中间层。程式代码会产生逻辑地址，或说是段中的偏移地址，加上相应段的基地址就生成了一个线性地址。如果启用了分页机制，那么线性地址能再经变换以产生一个物理地址。若没有启用分页机制，那么线性地址直接就是物理地址。Intel 80386 的线性地址空间容量为 4G（2的32次方即32根地址总线寻址）。</p>
</blockquote>
<blockquote>
<p><strong>物理地址（Physical Address）</strong> 是指出目前 CPU 外部地址总线上的寻址物理内存的地址信号，是地址变换的最终结果地址。如果启用了分页机制，那么线性地址会使用页目录和页表中的项变换成物理地址。如果没有启用分页机制，那么线性地址就直接成为物理地址了。</p>
</blockquote>
<blockquote>
<p><strong>虚拟内存（Virtual Memory）</strong>是指计算机呈现出要比实际拥有的内存大得多的内存量。因此他允许程式员编制并运行比实际系统拥有的内存大得多的程式。这使得许多大型项目也能够在具有有限内存资源的系统上实现。一个非常恰当的比喻是：你不必非常长的轨道就能让一列火车从上海开到北京。你只需要足够长的铁轨（比如说3公里）就能完成这个任务。采取的方法是把后面的铁轨即时铺到火车的前面，只要你的操作足够快并能满足需求，列车就能象在一条完整的轨道上运行。这也就是虚拟内存管理需要完成的任务。在 Linux0.11 内核中，给每个程式（进程）都划分了总容量为 64MB 的虚拟内存空间。因此程式的逻辑地址范围是 0x0000000 到 0x4000000。<strong>有时我们也把逻辑地址称为 虚拟地址。</strong>因为和虚拟内存空间的概念类似，逻辑地址也是和实际物理内存容量无关的。逻辑地址和物理地址的“差距”是 0xC0000000，是由于虚拟地址-&gt;线性地址-&gt;物理地址映射正好差这个值。这个值是由操作系统指定的。机理逻辑地址（或称为虚拟地址）到线性地址是由CPU的段机制自动转换的。如果没有开启分页管理，则线性地址就是物理地址。如果开启了分页管理，那么系统程式需要参和线性地址到物理地址的转换过程。具体是通过设置页目录表和页表项进行的。</p>
</blockquote>
<p>更详细的地址空间和虚拟内存知识请看<a href="https://blog.csdn.net/tennysonsky/article/details/45092229">浅谈进程地址空间与虚拟存储空间</a></p>
<h2 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h2><p>如前所述，操作系统的一项主要功能是屏蔽磁盘和其他 I&#x2F;O 设备的细节特性，给程序员提供一个良好、清晰的独立于设备的抽象文件模型。创建文件、删除文件、读文件和写文件 都需要系统调用。在文件可以读取之前，必须先在磁盘上定位和打开文件，在文件读过之后应该关闭该文件，有关的系统调用则用于完成这类操作。</p>
<p>为了提供保存文件的地方，大多数个人计算机操作系统都有目录(directory) 的概念，从而可以把文件分组。比如，学生可以给每个课程都创建一个目录，用于保存该学科的资源，另一个目录可以存放电子邮件，再有一个目录可以存放万维网主页。这就需要系统调用创建和删除目录、将已有文件放入目录中，从目录中删除文件等。目录项可以是文件或者目录，目录和目录之间也可以嵌套，这样就产生了文件系统</p>
<p>进程和文件层次都是以树状的结构组织，但这两种树状结构有不少不同之处。一般进程的树状结构层次不深（很少超过三层），而文件系统的树状结构要深一些，通常会到四层甚至五层。进程树层次结构是暂时的，通常最多存在几分钟，而目录层次则可能存在很长时间。进程和文件在权限保护方面也是有区别的。一般来说，父进程能控制和访问子进程，而在文件和目录中通常存在一种机制，使文件所有者之外的其他用户也能访问该文件。</p>
<p>目录层结构中的每一个文件都可以通过从目录的顶部即 根目录(Root directory) 开始的路径名(path name) 来确定。绝对路径名包含了从根目录到该文件的所有目录清单，它们之间用斜杠分隔符分开。</p>
<p><img src="https://pic.leetcode-cn.com/1612664781-pMUBso-os1-17.png"></p>
<p>在读写文件之前，首先需要打开文件，检查其访问权限。若权限许可，系统将返回一个小整数，称作文件描述符(file descriptor)，供后续操作使用。若禁止访问，系统则返回一个错误码。</p>
<p>在 UNIX 中，另一个重要的概念是 <strong>特殊文件(special file)<strong>。提供特殊文件是为了使 I&#x2F;O 设备看起来像文件一般。这样，就像使用系统调用读写文件一样，I&#x2F;O 设备也可以通过同样的系统调用进行读写。特殊文件有两种，一种是</strong>块特殊文件(block special file)</strong> 和 **字符特殊文件(character special file)**。块特殊文件指那些由可随机存取的块组成的设备，如磁盘等。比如打开一个块特殊文件，然后读取第 4 块，程序可以直接访问设备的第 4 块而不必考虑存放在该文件的文件系统结构。类似的，字符特殊文件用于打印机、调制解调起和其他接受或输出字符流的设备。按照惯例，特殊文件保存在 &#x2F;dev 目录中。例如，&#x2F;devv&#x2F;lp 是打印机.</p>
<h3 id="管道-进程间通信方式"><a href="#管道-进程间通信方式" class="headerlink" title="管道-进程间通信方式"></a>管道-进程间通信方式</h3><p>管道(pipe) 是一种虚文件，他可以连接两个进程。<br><img src="https://pic.leetcode-cn.com/1612664786-aXeXlC-os1-18.png"><br>如果 A 和 B 希望通过管道对话，他们必须提前设置管道。当进程 A 相对进程 B 发送数据时，它把数据写到管道上，相当于管道就是输出文件。这样，在 UNIX 中两个进程之间的通信就非常类似于普通文件的读写了。</p>
<p>详细的管道知识见<a href="https://ty-chen.github.io/linux-kernel-pipe/">进程间通信之管道</a></p>
<h2 id="文件保护"><a href="#文件保护" class="headerlink" title="文件保护"></a>文件保护</h2><p>计算机中含有大量的信息，用户希望能够对这些信息中有用而且重要的信息加以保护，这些信息包括电子邮件、商业计划等，管理这些信息的安全性完全依靠操作系统来保证。例如，文件提供授权用户访问。</p>
<p>比如 UNIX 操作系统，UNIX 操作系统通过对每个文件赋予一个 9 位二进制保护代码，对 UNIX 中的文件实现保护。该保护代码有三个位子段，一个用于所有者，一个用于与所有者同组（用户被系统管理员划分成组）的其他成员，一个用于其他人。每个字段中有一位用于读访问，一位用于写访问，一位用于执行访问。这些位就是著名的 rwx位。例如，保护代码 rwxr-x–x 的含义是所有者可以读、写或执行该文件，其他的组成员可以读或执行（但不能写）此文件、而其他人可以执行（但不能读和写）该文件。</p>
<blockquote>
<p>数字模式：<br>    用 0~7 来表示 rwx，给每一种权限赋予不同的值：r 值 4，w 值 2，x 值 1，如：rwxr-x–x 用数字模式表示则为 751</p>
</blockquote>
<blockquote>
<p>二进制，拥有对应权限的位为1，无权限为0。<br>    只拥有r权限，二进制是100，10进制是4<br>    只有用w权限，二进制是010，10进制是2<br>    只有用x权限，二进制是001，10进制是1<br>    拥有多个权限的，数值相加</p>
</blockquote>
<h2 id="shell"><a href="#shell" class="headerlink" title="shell"></a>shell</h2><p>操作系统是执行系统调用的代码。编辑器、编译器、汇编程序、链接程序、使用程序以及命令解释符等，尽管非常重要，非常有用，但是它们确实不是操作系统的组成部分。下面我们着重介绍一下 UNIX 下的命令提示符，也就是 shell，shell 虽然有用，但它也不是操作系统的一部分，然而它却能很好的说明操作系统很多特性，下面我们就来探讨一下。</p>
<p>shell 有许多种，例如 sh、csh、ksh 以及 bash等，它们都支持下面这些功能，最早起的 shell 可以追溯到 sh</p>
<p>用户登录时，会同时启动一个 shell，它以终端作为标准输入和标准输出。首先显示提示符(prompt)，它可能是一个美元符号($)，提示用户 shell 正在等待接收命令，假如用户输入<br><code> date</code><br>shell 会创建一个子进程，并运行 date 做为子进程。在该子进程运行期间，shell 将等待它结束。在子进程完成时，shell 会显示提示符并等待下一行输入。<br>用户可以将标准输出重定向到一个文件中，例如<br><code> date &gt; file</code></p>
<p>同样的，也可以将标准输入作为重定向<br><code> sort &lt;file1&gt; file2</code></p>
<p>这会调用 sort 程序来接收 file1 的内容并把结果输出到 file2。<br>可以将一个应用程序的输出通过管道作为另一个程序的输入，因此有<br><code> cat file1 file2 file3 | sort &gt; /dev/lp</code></p>
<p>这会调用 cat 应用程序来合并三个文件，将其结果输送到 sort 程序中并按照字典进行排序。sort 应用程序又被重定向到 &#x2F;dev&#x2F;lp ，显然这是一个打印操作。</p>
<blockquote>
<p>重定向 &gt; 是将输出定向到文件，如：command &gt; file<br>管道符 | 是将第一个命令的输出定向到第二个命令，如：command1 | command2</p>
</blockquote>
<h1 id="操作系统结构"><a href="#操作系统结构" class="headerlink" title="操作系统结构"></a>操作系统结构</h1><p>下面我们会探讨操作系统的几种结构，主要包括单体结构、分层系统、微内核、客户-服务端系统、虚拟机和外核等。下面以此来探讨一下</p>
<h2 id="单体结构"><a href="#单体结构" class="headerlink" title="单体结构"></a>单体结构</h2><p>到目前为止，在大多数系统中，整个系统在内核态以单一程序的方式运行。整个操作系统是以程序集合来编写的，链接在一块形成一个大的二进制可执行程序。使用此技术时，如果系统中的每个过程都提供了前者所需的一些有用的计算，则它可以自由调用任何其他过程。在单体系统中，调用任何一个所需要的程序都非常高效，但是上千个不受限制的彼此调用往往非常臃肿和笨拙，而且单体系统必然存在单体问题，那就是只要系统发生故障，那么任何系统和应用程序将不可用，这往往是灾难性的。</p>
<p>在单体系统中构造实际目标程序时，会首先编译所有单个过程（或包含这些过程的文件），然后使用系统链接器将它们全部绑定到一个可执行文件中</p>
<p>对于单体系统，往往有下面几种建议</p>
<p>需要有一个主程序，用来调用请求服务程序<br>需要一套服务过程，用来执行系统调用<br>需要一套实用过程，用来辅助服务过程调用<br>在单体系统中，对于每个系统调用都会有一个服务程序来保障和运行。需要一组实用程序来弥补服务程序需要的功能，例如从用户程序中获取数据。可将各种过程划分为一个三层模型</p>
<p><img src="https://pic.leetcode-cn.com/1612664809-wPUAwa-os1-24.png"><br>除了在计算机初启动时所装载的核心操作系统外，许多操作系统还支持额外的扩展。比如 I&#x2F;O 设备驱动和文件系统。这些部件可以按需装载。在 UNIX 中把它们叫做 共享库(shared library)，在 Windows 中则被称为 动态链接库(Dynamic Link Library,DLL)。他们的扩展名为 .dll，在 C:\Windows\system32 目录下存在 1000 多个 DLL 文件，所以不要轻易删除 C 盘文件.</p>
<h2 id="分层结构"><a href="#分层结构" class="headerlink" title="分层结构"></a>分层结构</h2><p>分层系统使用层来分隔不同的功能单元。每一层只与该层的上层和下层通信。每一层都使用下面的层来执行其功能。层之间的通信通过预定义的固定接口通信。</p>
<h2 id="微内核"><a href="#微内核" class="headerlink" title="微内核"></a>微内核</h2><p>在分层方式中，设计者要确定在哪里划分 内核-用户 的边界。传统上，所有的层都在内核中，但是这样做没有必要。事实上，尽可能减少内核态中功能可能是更好的做法。因为内核中的错误很难处理，一旦内核态中出错误会拖累整个系统。</p>
<p>所以，为了实现高可靠性，将操作系统划分成小的、层级之间能够更好定义的模块是很有必要的，只有一个模块 — 微内核 — 运行在内核态，其余模块可以作为普通用户进程运行。由于把每个设备驱动和文件系统分别作为普通用户进程，这些模块中的错误虽然会使这些模块崩溃，但是不会使整个系统死机。</p>
<p>MINIX 3 是微内核的代表作，它的具体结构如下<br><img src="https://pic.leetcode-cn.com/1612664817-eEESEM-os1-26.png"><br>在内核的外部，系统的构造有三层，它们都在用户态下运行，最底层是设备驱动器。由于它们都在用户态下运行，所以不能物理的访问 I&#x2F;O 端口空间，也不能直接发出 I&#x2F;O 命令。相反，为了能够对 I&#x2F;O 设备编程，驱动器构建一个结构，指明哪个参数值写到哪个 I&#x2F;O 端口，并声称一个内核调用，这样就完成了一次调用过程。</p>
<p>位于用户态的驱动程序上面是服务器层，包含有服务器，它们完成操作系统的多数工作。由一个或多个文件服务器管理着文件系统，进程管理器创建、销毁和管理进程。服务器中有一个特殊的服务器称为 再生服务器(reincarnation server)，它的任务就是检查服务器和驱动程序的功能是否正确，一旦检查出来错误，它就会补上去，无需用户干预。这种方式使得系统具有可恢复性，并具有较高的可靠性。</p>
<p>微内核中的内核还具有一种 机制 与 策略 分离的思想。比如系统调度，一个比较简单的调度算法是，对每个进程赋予一个优先级，并让内核执行具有最高优先级的进程。这里，内核机制就是寻找最高的优先级进程并运行。而策略（赋予进程优先级）可以在用户态中的进程完成。在这种模式中，策略和机制是分离的，从而使内核变得更小。</p>
<h2 id="客户-服务器模式"><a href="#客户-服务器模式" class="headerlink" title="客户-服务器模式"></a>客户-服务器模式</h2><p>微内核思想的策略是把进程划分为两类：服务器，每个服务器用来提供服务；客户端，使用这些服务。这个模式就是所谓的 客户-服务器模式。</p>
<p>客户-服务器模式会有两种载体，一种情况是一台计算机既是客户又是服务器，在这种方式下，操作系统会有某种优化；但是普遍情况下是客户端和服务器在不同的机器上，它们通过局域网或广域网连接。</p>
<p><img src="https://pic.leetcode-cn.com/1612664821-fwqldX-os1-27.png"><br>客户通过发送消息与服务器通信，客户端并不需要知道这些消息是在本地机器上处理，还是通过网络被送到远程机器上处理。对于客户端而言，这两种情形是一样的：都是发送请求并得到回应。</p>
<p>越来越多的系统，包括家里的 PC，都成为客户端，而在某地运行的大型机器则成为服务器。许多 web 就是以这种方式运行的。一台 PC 向某个服务器请求一个 Web 页面，服务器把 Web 页面返回给客户端，这就是典型的客服-服务器模式</p>
]]></content>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统笔记（3）- 进程和线程</title>
    <url>/2022/08/31/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0-%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="进程和线程"><a href="#进程和线程" class="headerlink" title="进程和线程"></a>进程和线程</h1><p><img src="https://pic.leetcode-cn.com/1612664902-lwiEpk-os2-0.png"></p>
<span id="more"></span>
<h2 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h2><p>操作系统中最核心的概念就是 进程，进程是对正在运行中的程序的一个抽象。操作系统的其他所有内容都是围绕着进程展开的。进程是操作系统提供的最古老也是最重要的概念之一。即使可以使用的 CPU 只有一个，它们也支持（伪）并发操作。它们会将一个单独的 CPU 抽象为多个虚拟机的 CPU。可以说：没有进程的抽象，现代操作系统将不复存在。</p>
<p><img src="https://pic.leetcode-cn.com/1612664905-eSWcTc-os2-1.png"><br>所有现代的计算机会在同一时刻做很多事情，过去使用计算机的人（单 CPU）可能完全无法理解现在这种变化，举个例子更能说明这一点：首先考虑一个 Web 服务器，请求都来自于 Web 网页。当一个请求到达时，服务器会检查当前页是否在缓存中，如果是在缓存中，就直接把缓存中的内容返回。如果缓存中没有的话，那么请求就会交给磁盘来处理。但是，从 CPU 的角度来看，磁盘请求需要更长的时间，因为磁盘请求会很慢。当硬盘请求完成时，更多其他请求才会进入。如果有多个磁盘的话，可以在第一个请求完成前就可以连续的对其他磁盘发出部分或全部请求。很显然，这是一种并发现象，需要有并发控制条件来控制并发现象。</p>
<p>现在考虑只有一个用户的 PC。当系统启动时，许多进程也在后台启动，用户通常不知道这些进程的启动，试想一下，当你自己的计算机启动的时候，你能知道哪些进程是需要启动的么？这些后台进程可能是一个需要输入电子邮件的电子邮件进程，或者是一个计算机病毒查杀进程来周期性的更新病毒库。某个用户进程可能会在所有用户上网的时候打印文件以及刻录 CD-ROM，这些活动都需要管理。于是一个支持多进程的多道程序系统就会显得很有必要了。</p>
<p>在许多多道程序系统中，CPU 会在进程间快速切换，使每个程序运行几十或者几百毫秒。然而，严格意义来说，在某一个瞬间，CPU 只能运行一个进程，然而我们如果把时间定位为 1 秒内的话，它可能运行多个进程。这样就会让我们产生并行的错觉。有时候人们说的 伪并行(pseudoparallelism) 就是这种情况，以此来区分多处理器系统(该系统由两个或多个 CPU 来共享同一个物理内存)</p>
<blockquote>
<p>再来详细解释一下伪并行：伪并行是指单核或多核处理器同时执行多个进程，从而使程序更快。 通过以非常有限的时间间隔在程序之间快速切换CPU，因此会产生并行感。 缺点是 CPU 时间可能分配给下一个进程，也可能不分配给下一个进程。</p>
</blockquote>
<p>因为 CPU 执行速度很快，进程间的换进换出也非常迅速，因此我们很难对多个并行进程进行跟踪，所以，在经过多年的努力后，操作系统的设计者开发了用于描述并行的一种概念模型（顺序进程），使得并行更加容易理解和分析，对该模型的探讨，也是本篇文章的主题。下面我们就来探讨一下进程模型</p>
<h3 id="进程模型"><a href="#进程模型" class="headerlink" title="进程模型"></a>进程模型</h3><p>在进程模型中，所有计算机上运行的软件，通常也包括操作系统，被组织为若干顺序进程(sequential processes)，简称为 进程(process) 。一个进程就是一个正在执行的程序的实例，进程也包括程序计数器、寄存器和变量的当前值。从概念上来说，每个进程都有各自的虚拟 CPU，但是实际情况是 CPU 会在各个进程之间进行来回切换</p>
<p><img src="https://pic.leetcode-cn.com/1612664908-dNSorg-os2-2.png"><br>如上图所示，这是一个具有 4 个程序的多道处理程序，在进程不断切换的过程中，程序计数器也在不同的变化。<br><img src="https://pic.leetcode-cn.com/1612664911-qLPkqU-os2-3.png"></p>
<p>在上图中，这 4 道程序被抽象为 4 个拥有各自控制流程（即每个自己的程序计数器）的进程，并且每个程序都独立的运行。当然，实际上只有一个物理程序计数器，每个程序要运行时，其逻辑程序计数器会装载到物理程序计数器中。当程序运行结束后，其物理程序计数器就会是真正的程序计数器，然后再把它放回进程的逻辑计数器中。</p>
<p>从下图我们可以看到，在观察足够长的一段时间后，所有的进程都运行了，但在任何一个给定的瞬间仅有一个进程真正运行。</p>
<p><img src="https://pic.leetcode-cn.com/1612664914-hXFqlB-os2-4.png"><br>因此，当我们说一个 CPU 只能真正一次运行一个进程的时候，即使有 2 个核（或 CPU），每一个核也只能一次运行一个进程。</p>
<p>由于 CPU 会在各个进程之间来回快速切换，所以每个进程在 CPU 中的运行时间是无法确定的。并且当同一个进程再次在 CPU 中运行时，其在 CPU 内部的运行时间往往也是不固定的。进程和程序之间的区别是非常微妙的，但是通过一个例子可以让你加以区分：想想一位会做饭的计算机科学家正在为他的女儿制作生日蛋糕。他有做生日蛋糕的食谱，厨房里有所需的原料：面粉、鸡蛋、糖、香草汁等。在这个比喻中，做蛋糕的食谱就是程序、计算机科学家就是 CPU、而做蛋糕的各种原料都是输入数据。进程就是科学家阅读食谱、取来各种原料以及烘焙蛋糕等一系例了动作的总和。</p>
<p>现在假设科学家的儿子跑过来告诉他，说他的头被蜜蜂蜇了一下，那么此时科学家会记录出来他做蛋糕这个过程到了哪一步，然后拿出急救手册，按照上面的步骤给他儿子实施救助。这里，会涉及到进程之间的切换，科学家（CPU）会从做蛋糕（进程）切换到实施医疗救助（另一个进程）。等待伤口处理完毕后，科学家会回到刚刚记录做蛋糕的那一步，继续制作。</p>
<p>这里的关键思想是认识到一个进程所需的条件，进程是某一类特定活动的总和，它有程序、输入输出以及状态。单个处理器可以被若干进程共享，它使用某种调度算法决定何时停止一个进程的工作，并转而为另外一个进程提供服务。另外需要注意的是，如果一个进程运行了两遍，则被认为是两个进程。那么我们了解到进程模型后，那么进程是如何创建的呢？</p>
<h3 id="进程的创建"><a href="#进程的创建" class="headerlink" title="进程的创建"></a>进程的创建</h3><p>进程在执行过程中可能创建多个新的进程。创建进程称为父进程，而新的进程称为子进程。每个新进程可以再创建其他进程，从而形成进程树。</p>
<p>大多数的操作系统（包括 UNIX、Linux 和 Windows）对进程的识别采用的是唯一的进程标识符（pid），pid 通常是一个整数值。系统内的每个进程都有一个唯一 pid，它可以用作索引，以便访问内核中的进程的各种属性。</p>
<p><img src="http://c.biancheng.net/uploads/allimg/181102/2-1Q1021100135W.gif"><br>上图显示了Linux操作系统的一个典型进程树，包括进程的名称和pid，进程init（它的pid总是1），作为所有用户进程的根进程或父进程。一旦系统启动后，进程init可以创建各种用户进程，如Web服务器、打印服务器、ssh服务器等.</p>
<p>上图中，kthreadd和sshd为init的两个子进程。kthreadd进程负责创建额外进程，以便执行内核任务（这里为khelper和pdflush）。sshd进程负责管理通过ssh连到系统的客户端。login进程负责管理直接登录到系统的客户端。在这个例子中，客户已登录，并且使用bash外壳，它所分配的pid为8416。采用bash命令行界面，这个进程还创建了进程ps和emacs编辑器。</p>
<p>一般来说，当一个进程创建子进程时，该子进程需要一定的资源（CPU 时间、内存、文件、I&#x2F;O 设备等）来完成任务。子进程可以从操作系统那里直接获得资源，也可以只从父进程那里获得资源子集。父进程可能要在子进程之间分配资源或共享资源（如内存或文件）。限制子进程只能使用父进程的资源，可以防止创建过多进程，导致系统超载。</p>
<p>除了提供各种物理和逻辑资源外，父进程也可能向子进程传递初始化数据（或输入）。例如，假设有一个进程，其功能是在终端屏幕上显示文件如image.jpg的状态。当该进程被创建时，它会从父进程处得到输入，即文件名称image.jpg。通过这个名称，它会打开文件，进而写出内容。它也可以得到输出设备名称。另外，有的操作系统会向子进程传递资源。对于这种系统，新进程可得到两个打开文件，即image.jpg和终端设备，并且可以在这两者之间进行数据传输。</p>
<p>当进程创建新进程时，可有两种执行可能：<br>父进程与子进程并发执行。<br>父进程等待，直到某个或全部子进程执行完。</p>
<p>新进程的地址空间也有两种可能：<br>子进程是父进程的复制品（它具有与父进程同样的程序和数据）[UNIX]。<br>子进程加载另一个新程序 [Windows]。</p>
<h3 id="进程终止"><a href="#进程终止" class="headerlink" title="进程终止"></a>进程终止</h3><p>进程在创建之后，它就开始运行并做完成任务。然而，没有什么事儿是永不停歇的，包括进程也一样。进程早晚会发生终止，但是通常是由于以下情况触发的</p>
<blockquote>
<p>正常退出(自愿的)<br>错误退出(自愿的)<br>严重错误(非自愿的)<br>被其他进程杀死(非自愿的)</p>
</blockquote>
<p>正常退出<br>多数进程是由于完成了工作而终止。当编译器完成了所给定程序的编译之后，编译器会执行一个系统调用告诉操作系统它完成了工作。这个调用在 UNIX 中是 exit ，在 Windows 中是 ExitProcess。面向屏幕中的软件也支持自愿终止操作。字处理软件、Internet 浏览器和类似的程序中总有一个供用户点击的图标或菜单项，用来通知进程删除它锁打开的任何临时文件，然后终止。</p>
<p>错误退出<br>进程发生终止的第二个原因是发现严重错误，例如，如果用户执行如下命令</p>
<p>cc foo.c	<br>为了能够编译 foo.c 但是该文件不存在，于是编译器就会发出声明并退出。在给出了错误参数时，面向屏幕的交互式进程通常并不会直接退出，因为这从用户的角度来说并不合理，用户需要知道发生了什么并想要进行重试，所以这时候应用程序通常会弹出一个对话框告知用户发生了系统错误，是需要重试还是退出。</p>
<p>严重错误<br>进程终止的第三个原因是由进程引起的错误，通常是由于程序中的错误所导致的。例如，执行了一条非法指令，引用不存在的内存，或者除数是 0 等。在有些系统比如 UNIX 中，进程可以通知操作系统，它希望自行处理某种类型的错误，在这类错误中，进程会收到信号（中断），而不是在这类错误出现时直接终止进程。</p>
<p>被其他进程杀死<br>第四个终止进程的原因是，某个进程执行系统调用告诉操作系统杀死某个进程。在 UNIX 中，这个系统调用是 kill。在 Win32 中对应的函数是 TerminateProcess（注意不是系统调用）。</p>
<h3 id="进程状态"><a href="#进程状态" class="headerlink" title="进程状态"></a>进程状态</h3><p>尽管每个进程是一个独立的实体，有其自己的程序计数器和内部状态，但是，进程之间仍然需要相互帮助。例如，一个进程的结果可以作为另一个进程的输入，在 shell 命令中</p>
<p>cat chapter1 chapter2 chapter3 | grep tree<br>第一个进程是 cat，将三个文件级联并输出。第二个进程是 grep，它从输入中选择具有包含关键字 tree 的内容，根据这两个进程的相对速度（这取决于两个程序的相对复杂度和各自所分配到的 CPU 时间片），可能会发生下面这种情况，grep 准备就绪开始运行，但是输入进程还没有完成，于是必须阻塞 grep 进程，直到输入完毕。</p>
<p>当一个进程开始运行时，它可能会经历下面这几种状态</p>
<p><img src="https://pic.leetcode-cn.com/1612664920-QftYDM-os2-6.png"><br>图中会涉及三种状态</p>
<p>运行态，运行态指的就是进程实际占用 CPU 时间片运行时<br>就绪态，就绪态指的是可运行，但因为其他进程正在运行而处于就绪状态<br>阻塞态，除非某种外部事件发生，否则进程不能运行<br>逻辑上来说，运行态和就绪态是很相似的。这两种情况下都表示进程可运行，但是第二种情况没有获得 CPU 时间分片。第三种状态与前两种状态不同的原因是这个进程不能运行，CPU 空闲时也不能运行。</p>
<p>三种状态会涉及四种状态间的切换，在操作系统发现进程不能继续执行时会发生状态1的轮转，在某些系统中进程执行系统调用，例如 pause，来获取一个阻塞的状态。在其他系统中包括 UNIX，当进程从管道或特殊文件（例如终端）中读取没有可用的输入时，该进程会被自动终止。</p>
<p>转换 2 和转换 3 都是由进程调度程序（操作系统的一部分）引起的，进程本身不知道调度程序的存在。转换 2 的出现说明进程调度器认定当前进程已经运行了足够长的时间，是时候让其他进程运行 CPU 时间片了。当所有其他进程都运行过后，这时候该是让第一个进程重新获得 CPU 时间片的时候了，就会发生转换 3。</p>
<p>程序调度指的是，决定哪个进程优先被运行和运行多久，这是很重要的一点。已经设计出许多算法来尝试平衡系统整体效率与各个流程之间的竞争需求。</p>
<p>当进程等待的一个外部事件发生时（如从外部输入一些数据后），则发生转换 4。如果此时没有其他进程在运行，则立刻触发转换 3，该进程便开始运行，否则该进程会处于就绪阶段，等待 CPU 空闲后再轮到它运行。</p>
<p>从上面的观点引入了下面的模型<br><img src="https://pic.leetcode-cn.com/1612664924-vtsYOD-os2-7.png"><br>操作系统最底层的就是调度程序，在它上面有许多进程。所有关于中断处理、启动进程和停止进程的具体细节都隐藏在调度程序中。事实上，调度程序只是一段非常小的程序。</p>
<h2 id="线程"><a href="#线程" class="headerlink" title="线程"></a>线程</h2><p>在传统的操作系统中，每个进程都有一个地址空间和一个控制线程。事实上，这是大部分进程的定义。不过，在许多情况下，经常存在同一地址空间中运行多个控制线程的情形，这些线程就像是分离的进程。下面我们就着重探讨一下什么是线程</p>
<h3 id="线程使用"><a href="#线程使用" class="headerlink" title="线程使用"></a>线程使用</h3><p>或许这个疑问也是你的疑问，为什么要在进程的基础上再创建一个线程的概念，准确的说，这其实是进程模型和线程模型的讨论，回答这个问题，可能需要分三步来回答</p>
<p>多线程之间会共享同一块地址空间和所有可用数据的能力，这是进程所不具备的<br>线程要比进程更轻量级，由于线程更轻，所以它比进程更容易创建，也更容易撤销。在许多系统中，创建一个线程要比创建一个进程快 10 - 100 倍。<br>第三个原因可能是性能方面的探讨，如果多个线程都是 CPU 密集型的，那么并不能获得性能上的增强，但是如果存在着大量的计算和大量的 I&#x2F;O 处理，拥有多个线程能在这些活动中彼此重叠进行，从而会加快应用程序的执行速度<br>多线程解决方案<br>现在考虑一个线程使用的例子：一个万维网服务器，对页面的请求发送给服务器，而所请求的页面发送回客户端。在多数 web 站点上，某些页面较其他页面相比有更多的访问。例如，索尼的主页比任何一个照相机详情介绍页面具有更多的访问，Web 服务器可以把获得大量访问的页面集合保存在内存中，避免到磁盘去调入这些页面，从而改善性能。这种页面的集合称为 高速缓存(cache)，高速缓存也应用在许多场合中，比如说 CPU 缓存。</p>
<h3 id="经典线程模型"><a href="#经典线程模型" class="headerlink" title="经典线程模型"></a>经典线程模型</h3><p>理解进程的另一个角度是，用某种方法把相关的资源集中在一起。进程有存放程序正文和数据以及其他资源的地址空间。这些资源包括打开的文件、子进程、即将发生的定时器、信号处理程序、账号信息等。把这些信息放在进程中会比较容易管理。</p>
<p>另一个概念是，进程中拥有一个执行的线程，通常简写为 线程(thread)。线程会有程序计数器，用来记录接着要执行哪一条指令；线程还拥有寄存器，用来保存线程当前正在使用的变量；线程还会有堆栈，用来记录程序的执行路径。尽管线程必须在某个进程中执行，但是进程和线程完完全全是两个不同的概念，并且他们可以分开处理。进程用于把资源集中在一起，而线程则是 CPU 上调度执行的实体。</p>
<p>线程给进程模型增加了一项内容，即在同一个进程中，允许彼此之间有较大的独立性且互不干扰。在一个进程中并行运行多个线程类似于在一台计算机上运行多个进程。在多个线程中，各个线程共享同一地址空间和其他资源。在多个进程中，进程共享物理内存、磁盘、打印机和其他资源。因为线程会包含有一些进程的属性，所以线程被称为轻量的进程(lightweight processes)。多线程(multithreading)一词还用于描述在同一进程中多个线程的情况。</p>
<p>下图我们可以看到三个传统的进程，每个进程有自己的地址空间和单个控制线程。每个线程都在不同的地址空间中运行<br><img src="https://pic.leetcode-cn.com/1612664935-VGJYJw-os2-10.png"><br>下图中，我们可以看到有一个进程三个线程的情况。每个线程都在相同的地址空间中运行<br><img src="https://pic.leetcode-cn.com/1612664939-ohBQvP-os2-11.png"><br>线程不像是进程那样具备较强的独立性。同一个进程中的所有线程都会有完全一样的地址空间，这意味着它们也共享同样的全局变量。由于每个线程都可以访问进程地址空间内每个内存地址，因此一个线程可以读取、写入甚至擦除另一个线程的堆栈。线程之间除了共享同一内存空间外，还具有如下不同的内容<br><img src="https://pic.leetcode-cn.com/1612664943-DhhTNi-os2-12.png"><br>上图左边的是同一个进程中每个线程共享的内容，上图右边是每个线程中的内容。也就是说左边的列表是进程的属性，右边的列表是线程的属性。</p>
<p>和进程一样，线程可以处于下面这几种状态：运行中、阻塞、就绪和终止（进程图中没有画）。正在运行的线程拥有 CPU 时间片并且状态是运行中。一个被阻塞的线程会等待某个释放它的事件。例如，当一个线程执行从键盘读入数据的系统调用时，该线程就被阻塞直到有输入为止。线程通常会被阻塞，直到它等待某个外部事件的发生或者有其他线程来释放它。线程之间的状态转换和进程之间的状态转换是一样的。</p>
<p>每个线程都会有自己的堆栈，如下图所示<br><img src="https://pic.leetcode-cn.com/1612664947-Hfgzjb-os2-13.png"></p>
<p><strong>线程系统调用</strong><br>进程通常会从当前的某个单线程开始，然后这个线程通过调用一个库函数（比如 thread_create ）创建新的线程。线程创建的函数会要求指定新创建线程的名称。创建的线程通常都返回一个线程标识符，该标识符就是新线程的名字。</p>
<p>当一个线程完成工作后，可以通过调用一个函数（比如 thread_exit）来退出。紧接着线程消失，状态变为终止，不能再进行调度。在某些线程的运行过程中，可以通过调用函数例如 thread_join ，表示一个线程可以等待另一个线程退出。这个过程阻塞调用线程直到等待特定的线程退出。在这种情况下，线程的创建和终止非常类似于进程的创建和终止。</p>
<p>另一个常见的线程是调用 thread_yield，它允许线程自动放弃 CPU 从而让另一个线程运行。这样一个调用还是很重要的，因为不同于进程，线程是无法利用时钟中断强制让线程让出 CPU 的。</p>
]]></content>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统笔记（4）- 进程间通信</title>
    <url>/2022/09/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E4%B8%8E%E8%B0%83%E5%BA%A6/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="进程间通信"><a href="#进程间通信" class="headerlink" title="进程间通信"></a>进程间通信</h1><p>进程是需要频繁的和其他进程进行交流的。例如，在一个 shell 管道中，第一个进程的输出必须传递给第二个进程，这样沿着管道进行下去。因此，进程之间如果需要通信的话，必须要使用一种良好的数据结构以至于不能被中断。下面我们会一起讨论有关 进程间通信(Inter Process Communication, IPC) 的问题。</p>
<span id="more"></span>
<p>关于进程间的通信，这里有三个问题</p>
<p>上面提到了第一个问题，那就是一个进程如何传递消息给其他进程。<br>第二个问题是如何确保两个或多个进程之间不会相互干扰。例如，两个航空公司都试图为不同的顾客抢购飞机上的最后一个座位。<br>第三个问题是数据的先后顺序的问题，如果进程 A 产生数据并且进程 B 打印数据。则进程 B 打印数据之前需要先等 A 产生数据后才能够进行打印。<br>需要注意的是，这三个问题中的后面两个问题同样也适用于线程</p>
<p>第一个问题在线程间比较好解决，因为它们共享一个地址空间，它们具有相同的运行时环境，可以想象你在用高级语言编写多线程代码的过程中，线程通信问题是不是比较容易解决？</p>
<p>另外两个问题也同样适用于线程，同样的问题可用同样的方法来解决。</p>
<h2 id="竞态条件"><a href="#竞态条件" class="headerlink" title="竞态条件"></a>竞态条件</h2><blockquote>
<p>竞态条件（race condition）指的是两个或者以上进程或者线程并发执行时，其最终的结果依赖于进程或者线程执行的精确时序。竞争条件会产生超出预期的情况，一般情况下我们都希望程序执行的结果是符合预期的，因此竞争条件是一种需要被避免的情形。</p>
</blockquote>
<p>在一些操作系统中，协作的进程可能共享一些彼此都能读写的公共资源。公共资源可能在内存中也可能在一个共享文件。为了讲清楚进程间是如何通信的，这里我们举一个例子：一个后台打印程序。当一个进程需要打印某个文件时，它会将文件名放在一个特殊的后台目录(spooler directory)中。另一个进程 打印后台进程(printer daemon) 会定期的检查是否需要文件被打印，如果有的话，就打印并将该文件名从目录下删除。</p>
<p>假设我们的后台目录有非常多的 槽位(slot)，编号依次为 0，1，2，…，每个槽位存放一个文件名。同时假设有两个共享变量：out，指向下一个需要打印的文件；in，指向目录中下个空闲的槽位。可以把这两个文件保存在一个所有进程都能访问的文件中，该文件的长度为两个字。在某一时刻，0 至 3 号槽位空，4 号至 6 号槽位被占用。在同一时刻，进程 A 和 进程 B 都决定将一个文件排队打印，情况如下</p>
<p><img src="https://pic.leetcode-cn.com/1612664963-hhHjky-os2-17.png"></p>
<p>可能会发生以下错误，进程 A 读到 in 的值为 7，将 7 存在一个局部变量 next_free_slot 中。此时发生一次时钟中断，CPU 认为进程 A 已经运行了足够长的时间，决定切换到进程 B 。进程 B 也读取 in 的值，发现是 7，然后进程 B 将 7 写入到自己的局部变量 next_free_slot 中，在这一时刻两个进程都认为下一个可用槽位是 7 。</p>
<p>进程 B 现在继续运行，它会将打印文件名写入到 slot 7 中，然后把 in 的指针更改为 8 ，然后进程 B 离开去做其他的事情</p>
<p>现在进程 A 开始恢复运行，由于进程 A 通过检查 next_free_slot也发现 slot 7 的槽位是空的，于是将打印文件名存入 slot 7 中，然后把 in 的值更新为 8 ，由于 slot 7 这个槽位中已经有进程 B 写入的值，所以进程 A 的打印文件名会把进程 B 的文件覆盖，由于打印机内部是无法发现是哪个进程更新的，它的功能比较局限，所以这时候进程 B 永远无法打印输出，类似这种情况，即两个或多个进程或线程同时对一共享数据进行修改，从而影响程序运行的正确性时，这种就被称为竞态条件(race condition)。调试竞态条件是一种非常困难的工作，因为绝大多数情况下程序运行良好，但在极少数的情况下会发生一些无法解释的奇怪现象。</p>
<h2 id="互斥条件"><a href="#互斥条件" class="headerlink" title="互斥条件"></a>互斥条件</h2><p>不仅共享资源会造成竞态条件，事实上共享文件、共享内存也会造成竞态条件、那么该如何避免呢？或许一句话可以概括说明：禁止一个或多个进程在同一时刻对共享资源（包括共享内存、共享文件等）进行读写。换句话说，我们需要一种 互斥(mutual exclusion) 条件，这也就是说，如果一个进程在某种方式下使用共享变量和文件的话，除该进程之外的其他进程就禁止做这种事（访问统一资源）。上面问题的纠结点在于，在进程 A 对共享变量的使用未结束之前进程 B 就使用它。在任何操作系统中，为了实现互斥操作而选用适当的原语是一个主要的设计问题，接下来我们会着重探讨一下。</p>
<p>避免竞争问题的条件可以用一种抽象的方式去描述。大部分时间，进程都会忙于内部计算和其他不会导致竞态条件的计算。然而，有时候进程会访问共享内存或文件，或者做一些能够导致竞态条件的操作。我们把对共享内存进行访问的程序片段称作 临界区域(critical region) 或 临界区(critical section)。如果我们能够正确的操作，使两个不同进程不可能同时处于临界区，就能避免竞争条件，这也是从操作系统设计角度来进行的。</p>
<p>尽管上面这种设计避免了竞态条件，但是不能确保并发进程同时访问共享数据的正确性和高效性。一个好的解决方案，应该包含下面四种条件</p>
<p>任何时候两个进程不能同时处于临界区<br>不应对 CPU 的速度和数量做任何假设<br>位于临界区外的进程不得阻塞其他进程<br>不能使任何进程无限等待进入临界区</p>
<p><img src="https://pic.leetcode-cn.com/1612664967-wcDqwh-os2-18.png"><br>从抽象的角度来看，我们通常希望进程的行为如上图所示，在 t1 时刻，进程 A 进入临界区，在 t2 的时刻，进程 B 尝试进入临界区，因为此时进程 A 正在处于临界区中，所以进程 B 会阻塞直到 t3 时刻进程 A 离开临界区，此时进程 B 能够允许进入临界区。最后，在 t4 时刻，进程 B 离开临界区，系统恢复到没有进程的原始状态。</p>
<h2 id="忙等待互斥"><a href="#忙等待互斥" class="headerlink" title="忙等待互斥"></a>忙等待互斥</h2><h3 id="屏蔽中断"><a href="#屏蔽中断" class="headerlink" title="屏蔽中断"></a>屏蔽中断</h3><p>在单处理器系统上，最简单的解决方案是让每个进程在进入临界区后立即屏蔽所有中断，并在离开临界区之前重新启用它们。屏蔽中断后，时钟中断也会被屏蔽。CPU 只有发生时钟中断或其他中断时才会进行进程切换。这样，在屏蔽中断后 CPU 不会切换到其他进程。所以，一旦某个进程屏蔽中断之后，它就可以检查和修改共享内存，而不用担心其他进程介入访问共享数据。</p>
<p>这个方案可行吗？进程进入临界区域是由谁决定的呢？不是用户进程吗？当进程进入临界区域后，用户进程关闭中断，如果经过一段较长时间后进程没有离开，那么中断不就一直启用不了，结果会如何？可能会造成整个系统的终止。而且如果是多处理器的话，屏蔽中断仅仅对执行 disable 指令的 CPU 有效。其他 CPU 仍将继续运行，并可以访问共享内存。</p>
<p>另一方面，对内核来说，当它在执行更新变量或列表的几条指令期间将中断屏蔽是很方便的。例如，如果多个进程处理就绪列表中的时候发生中断，则可能会发生竞态条件的出现。所以，屏蔽中断对于操作系统本身来说是一项很有用的技术，但是对于用户线程来说，屏蔽中断却不是一项通用的互斥机制</p>
<h3 id="锁变量"><a href="#锁变量" class="headerlink" title="锁变量"></a>锁变量</h3><p>作为第二种尝试，可以寻找一种软件层面解决方案。考虑有单个共享的（锁）变量，初始为值为 0 。当一个线程想要进入关键区域时，它首先会查看锁的值是否为 0 ，如果锁的值是 0 ，进程会把它设置为 1 并让进程进入关键区域。如果锁的状态是 1，进程会等待直到锁变量的值变为 0 。因此，锁变量的值是 0 则意味着没有线程进入关键区域。如果是 1 则意味着有进程在关键区域内。我们对上图修改后，如下所示</p>
<p><img src="https://pic.leetcode-cn.com/1612664971-FTlkyU-os2-19.png"><br>这种设计方式是否正确呢？是否存在纰漏呢？假设一个进程读出锁变量的值并发现它为 0 ，而恰好在它将其设置为 1 之前，另一个进程调度运行，读出锁的变量为0 ，并将锁的变量设置为 1 。然后第一个线程运行，把锁变量的值再次设置为 1，此时，临界区域就会有两个进程在同时运行。</p>
<p><img src="https://pic.leetcode-cn.com/1612664975-miakCV-os2-20.png"><br>也许有的读者可以这么认为，在进入前检查一次，在要离开的关键区域再检查一次不就解决了吗？实际上这种情况也是于事无补，因为在第二次检查期间其他线程仍有可能修改锁变量的值，换句话说，这种 set-before-check 不是一种 原子性 操作，所以同样还会发生竞争条件。</p>
<h3 id="严格轮询法"><a href="#严格轮询法" class="headerlink" title="严格轮询法"></a>严格轮询法</h3><p>第三种互斥的方式先抛出来一段代码，这里的程序是用 C 语言编写，之所以采用 C 是因为操作系统普遍是用 C 来编写的（偶尔会用 C++），而基本不会使用 Java 、Modula3 或 Pascal 这样的语言，Java 中的 native 关键字底层也是 C 或 C++ 编写的源码。对于编写操作系统而言，需要使用 C 语言这种强大、高效、可预知和有特性的语言，而对于 Java ，它是不可预知的，因为它在关键时刻会用完存储器，而在不合适的时候会调用垃圾回收机制回收内存。在 C 语言中，这种情况不会发生，C 语言中不会主动调用垃圾回收回收内存。</p>
<p>进程0</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span>(TRUE) &#123;    </span><br><span class="line">    <span class="keyword">while</span>(turn != <span class="number">0</span>);    </span><br><span class="line">    critical_region();    </span><br><span class="line">    turn = <span class="number">1</span>;   </span><br><span class="line">    noncritical_region();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>进程1</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span>(TRUE) &#123;   </span><br><span class="line">    <span class="keyword">while</span>(turn != <span class="number">1</span>);    </span><br><span class="line">    critical_region();    </span><br><span class="line">    turn = <span class="number">0</span>;    </span><br><span class="line">    noncritical_region();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在上面代码中，变量 turn，初始值为 0 ，用于记录轮到那个进程进入临界区，并检查或更新共享内存。开始时，进程 1 检查 turn，发现其值为 0 ，于是进入临界区。进程 0 也发现其值为 0 ，所以在一个等待循环中不停的测试 turn，看其值何时变为 1。连续检查一个变量直到某个值出现为止，这种方法称为 忙等待(busywaiting)。由于这种方式浪费 CPU 时间，所以这种方式通常应该要避免。只有在有理由认为等待时间是非常短的情况下，才能够使用忙等待。用于忙等待的锁，称为 自旋锁(spinlock)。</p>
<p>进程 0 离开临界区时，它将 turn 的值设置为 1，以便允许进程 1 进入其临界区。假设进程 1 很快便离开了临界区，则此时两个进程都处于临界区之外，turn 的值又被设置为 0 。现在进程 0 很快就执行完了整个循环，它退出临界区，并将 turn 的值设置为 1。此时，turn 的值为 1，两个进程都在其临界区外执行。</p>
<p>突然，进程 0 结束了非临界区的操作并返回到循环的开始。但是，这时它不能进入临界区，因为 turn 的当前值为 1，此时进程 1 还忙于非临界区的操作，进程 0 只能继续 while 循环，直到进程 1 把 turn 的值改为 0 。这说明，在一个进程比另一个进程执行速度慢了很多的情况下，轮流进入临界区并不是一个好的方法。</p>
<p>这种情况违反了前面的叙述 3 ，即 位于临界区外的进程不得阻塞其他进程，进程 0 被一个临界区外的进程阻塞。由于违反了第三条，所以也不能作为一个好的方案。</p>
<h3 id="Peterson-解法"><a href="#Peterson-解法" class="headerlink" title="Peterson 解法"></a>Peterson 解法</h3><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> FALSE 0</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> TRUE  1</span></span><br><span class="line"><span class="comment">/* 进程数量 */</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> N     2													</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* 现在轮到谁 */</span></span><br><span class="line"><span class="type">int</span> turn;					</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 所有值初始化为 0 (FALSE) */</span></span><br><span class="line"><span class="type">int</span> interested[N];											</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 进程是 0 或 1 */</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">enter_region</span><span class="params">(<span class="type">int</span> process)</span>&#123;					</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/* 另一个进程号 */</span></span><br><span class="line">  <span class="type">int</span> other;														</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/* 另一个进程 */</span></span><br><span class="line">  other = <span class="number">1</span> - process;				</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/* 表示愿意进入临界区 */</span></span><br><span class="line">  interested[process] = TRUE;						</span><br><span class="line">  turn = process;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/* 空循环 */</span></span><br><span class="line">  <span class="keyword">while</span>(turn == process </span><br><span class="line">        &amp;&amp; interested[other] == <span class="literal">true</span>)&#123;&#125; </span><br><span class="line">  </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">leave_region</span><span class="params">(<span class="type">int</span> process)</span>&#123;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/* 表示离开临界区 */</span></span><br><span class="line">  interested[process] == FALSE;				 </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在使用共享变量时（即进入其临界区）之前，各个进程使用各自的进程号 0 或 1 作为参数来调用 enter_region，这个函数调用在需要时将使进程等待，直到能够安全的临界区。在完成对共享变量的操作之后，进程将调用 leave_region 表示操作完成，并且允许其他进程进入。</p>
<p>现在来看看这个办法是如何工作的。一开始，没有任何进程处于临界区中，现在进程 0 调用 enter_region。它通过设置数组元素和将 turn 置为 0 来表示它希望进入临界区。由于进程 1 并不想进入临界区，所以 enter_region 很快便返回。如果进程现在调用 enter_region，进程 1 将在此处挂起直到 interested[0] 变为 FALSE，这种情况只有在进程 0 调用 leave_region 退出临界区时才会发生。</p>
<p>那么上面讨论的是顺序进入的情况，现在来考虑一种两个进程同时调用 enter_region 的情况。它们都将自己的进程存入 turn，但只有最后保存进去的进程号才有效，前一个进程的进程号因为重写而丢失。假如进程 1 是最后存入的，则 turn 为 1 。当两个进程都运行到 while 的时候，进程 0 将不会循环并进入临界区，而进程 1 将会无限循环且不会进入临界区，直到进程 0 退出位置。</p>
<h2 id="睡眠与唤醒"><a href="#睡眠与唤醒" class="headerlink" title="睡眠与唤醒"></a>睡眠与唤醒</h2><p>上面解法中的 Peterson 、TSL 和 XCHG 解法都是正确的，但是它们都有忙等待的缺点。这些解法的本质上都是一样的，先检查是否能够进入临界区，若不允许，则该进程将原地等待，直到允许为止。</p>
<p>这种方式不但浪费了 CPU 时间，而且还可能引起意想不到的结果。考虑一台计算机上有两个进程，这两个进程具有不同的优先级，H 是属于优先级比较高的进程，L 是属于优先级比较低的进程。进程调度的规则是不论何时只要 H 进程处于就绪态 H 就开始运行。在某一时刻，L 处于临界区中，此时 H 变为就绪态，准备运行（例如，一条 I&#x2F;O 操作结束）。现在 H 要开始忙等，但由于当 H 就绪时 L 就不会被调度，L 从来不会有机会离开关键区域，所以 H 会变成死循环，有时将这种情况称为优先级反转问题(priority inversion problem)。</p>
<p>现在让我们看一下进程间的通信原语，这些原语在不允许它们进入关键区域之前会阻塞而不是浪费 CPU 时间，最简单的是 sleep 和 wakeup。Sleep 是一个能够造成调用者阻塞的系统调用，也就是说，这个系统调用会暂停直到其他进程唤醒它。wakeup 调用有一个参数，即要唤醒的进程。还有一种方式是 wakeup 和 sleep 都有一个参数，即 sleep 和 wakeup 需要匹配的内存地址。</p>
<h3 id="生产者与消费者问题"><a href="#生产者与消费者问题" class="headerlink" title="生产者与消费者问题"></a>生产者与消费者问题</h3><p>作为这些私有原语的例子，让我们考虑生产者-消费者(producer-consumer) 问题，也称作 有界缓冲区(bounded-buffer) 问题。两个进程共享一个公共的固定大小的缓冲区。其中一个是生产者(producer)，将信息放入缓冲区， 另一个是消费者(consumer) ，会从缓冲区中取出。也可以把这个问题一般化为 m 个生产者和 n 个消费者的问题，但是我们这里只讨论一个生产者和一个消费者的情况，这样可以简化实现方案。</p>
<p>如果缓冲队列已满，那么当生产者仍想要将数据写入缓冲区的时候，会出现问题。它的解决办法是让生产者睡眠，也就是阻塞生产者。等到消费者从缓冲区中取出一个或多个数据项时再唤醒它。同样的，当消费者试图从缓冲区中取数据，但是发现缓冲区为空时，消费者也会睡眠，阻塞。直到生产者向其中放入一个新的数据。</p>
<p>这个逻辑听起来比较简单，而且这种方式也需要一种称作 监听 的变量，这个变量用于监视缓冲区的数据，我们暂定为 count，如果缓冲区最多存放 N 个数据项，生产者会每次判断 count 是否达到 N，否则生产者向缓冲区放入一个数据项并增量 count 的值。消费者的逻辑也很相似：首先测试 count 的值是否为 0 ，如果为 0 则消费者睡眠、阻塞，否则会从缓冲区取出数据并使 count 数量递减。每个进程也会检查检查是否其他线程是否应该被唤醒，如果应该被唤醒，那么就唤醒该线程。</p>
<p>现在让我们回到生产者-消费者问题上来，上面代码中会产生竞态条件，因为 count 这个变量是暴露在大众视野下的。有可能出现下面这种情况：</p>
<blockquote>
<p>消费者发现count&#x3D;0时，刚要执行sleep()时，可能它的CPU时间到了，轮到了生产者去生产数据，生产者会发现之前没有数据，推测消费者睡了，于是要叫醒他。<br>这时消费者还没开始睡，轮到消费者时，它开始正式睡了。睡了就没人消费了呗，然后数据越来越多，生产者也睡了。<br>主要矛盾点，在于消费者获得count这个量时要执行的内容，被生产者打断了（没睡）。<br>所以需要，在count这个量上有一个独占性，或者说所有涉及共同分享的量。在执行这些量的相关操作时，应该只有一个进程能运行。<br>引起上面问题的本质是 唤醒尚未进行睡眠状态的进程会导致唤醒丢失。如果它没有丢失，则一切都很正常。一种快速解决上面问题的方式是增加一个唤醒等待位(wakeup waiting bit)。当一个 wakeup 信号发送给仍在清醒的进程后，该位置为 1 。之后，当进程尝试睡眠的时候，如果唤醒等待位为 1 ，则该位清除，而进程仍然保持清醒。</p>
</blockquote>
<p>然而，当进程数量有许多的时候，这时你可以说通过增加唤醒等待位的数量来唤醒等待位，于是就有了 2、4、6、8 个唤醒等待位，但是并没有从根本上解决问题。</p>
<h2 id="信号量"><a href="#信号量" class="headerlink" title="信号量"></a>信号量</h2><p>信号量就是在一个叫做互斥区的门口放一个盒子，盒子里面装着固定数量的小球，每个线程过来的时候，都从盒子里面摸走一个小球，然后去互斥区里面浪（？），浪开心了出来的时候，再把小球放回盒子里。如果一个线程走过来一摸盒子，得，一个球都没了，不拿球不让进啊，那就只能站在门口等一个线程出来放回来一个球，再进去。这样由于小球的数量是固定的，那么互斥区里面的最大线程数量就是固定的，不会出现一下进去太多线程把互斥区给挤爆了的情况。这是用信号量做并发量限制。另外一些情况下，小球是一次性的，线程拿走一个进了门，就把小球扔掉了，这样用着用着小球就没了，不过有另外一些线程（一般叫做生产者）会时不时过来往盒子里再放几个球，这样就可以有新的线程（一般叫做消费者）进去了，放一个球进一个线程，这是信号量做同步功能。你截图里的例子就是这个情况，主线程是生产者，通过sem_post往盒子里放小球（信号量加一），而其他线程是消费者，通过sem_wait从盒子里拿小球（信号量减一），如果遇到盒子里一个小球都没有（信号量为0），就会开始等待信号量不为0，然后拿走一个小球（信号量减一）再继续。本质上来说信号量就是那个盒子，以及“摸不到球就不让进”这个机制</p>
<h2 id="互斥量"><a href="#互斥量" class="headerlink" title="互斥量"></a>互斥量</h2><p>互斥量(Mutex)从本质上说是一把锁，在访问共享资源前对互斥量进行加锁，在访问完成后释放锁。当我们对互斥量进行加锁之后，任何其他试图再次对互斥量加锁的线程都会被阻塞直到当前线程释放该互斥锁。如果释放互斥量时有一个以上的线程阻塞，那么所有之前尝试对互斥量加锁的线程都会变成可运行状态，当第一个变为可运行的线程对互斥量加锁后，其他线程只能再次阻塞。在这种方式下，每次只有一个线程可以向前执行。<br><img src="https://pic.leetcode-cn.com/1612664980-cgqSLo-os2-21.png"></p>
<h3 id="Futex"><a href="#Futex" class="headerlink" title="Futex"></a>Futex</h3><p>随着并行的增加，有效的同步(synchronization)和锁定(locking) 对于性能来说是非常重要的。如果进程等待时间很短，那么自旋锁(Spin lock) 是非常有效；但是如果等待时间比较长，那么这会浪费 CPU 周期。如果进程很多，那么阻塞此进程，并仅当锁被释放的时候让内核解除阻塞是更有效的方式。不幸的是，这种方式也会导致另外的问题：它可以在进程竞争频繁的时候运行良好，但是在竞争不是很激烈的情况下内核切换的消耗会非常大，而且更困难的是，预测锁的竞争数量更不容易。</p>
<p>有一种有趣的解决方案是把两者的优点结合起来，提出一种新的思想，称为 futex，或者是 快速用户空间互斥(fast user space mutex)。</p>
<p>1.互斥锁或者计数锁，是阻塞式的，锁上会有一个等待队列。组建、检查或更新这个队列是需要从用户态切回内核态的，当竞争本身不激烈的时候，会有很大代价花在这个系统调用上。<br>2. futex是乐观的mutex,预期不会等待太长，所以先试试busy_waiting，这样不需要去触发系统调用，如果等了一段时间等不着，再去做系统调用相关的队列操作。<br>3. spinlock本身是会导致可能的CPU时间浪费，而阻塞式互斥锁则可能会花费太多时间在系统调用的切换上。因而futex是一个中间产物，试图平衡这两种的损耗。</p>
]]></content>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
</search>
